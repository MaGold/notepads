{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change of basis stuff\n",
    "\n",
    "Given basis $\\{a_1, a_2\\}, \\{b_1, b_n\\}$, we can convert via\n",
    "\n",
    "$a_1 = p_{11}b_1 + p_{21}b_2$\n",
    "\n",
    "$a_2 = p_{12}b_1 + p_{22}b_2$\n",
    "\n",
    "i.e. $a_1$ is worth $p_{11}$ of $b_1$, and $p_{12}$ of $b_2$. These are the coordinates of $a_1$ in $b$ land.\n",
    "\n",
    "So the matrix $P = \\begin{pmatrix} p_{11} & p_{12}\\\\ p_{21} & p_{22} \\end{pmatrix}$ (which looks like the transpose of the stuff above) converts $a_i$'s to $b_i$'s:\n",
    "\n",
    "$$Pa_1 = \\begin{pmatrix} p_{11} & p_{12}\\\\ p_{21} & p_{22} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} p_{11} \\\\ p_{21} \\end{pmatrix}$$ \n",
    "\n",
    "In the case where $b_1 = (1,0), b_2 = (0,1)$ we have $P = \\begin{pmatrix} | & | \\\\ a_1 & a_2 \\\\ | & | \\end{pmatrix}$, so that $Pa_1 = \\begin{pmatrix} | & | \\\\ a_1 & a_2 \\\\ | & | \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} | \\\\ a_1 \\\\ | \\end{pmatrix}$. This converts $a$'s to the standard basis. To do the opposite, i.e. standard basis to $a$'s, we use $P^{-1}$. In the case that the $a$'s are orthonormal, the inverse matrix will be the (conjugate) transpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear transforms as matrices\n",
    "\n",
    "Given $T$ and basis $\\alpha_1, \\alpha_2$, can write\n",
    "\n",
    "$ T \\alpha_1 = A_{11} \\alpha_1 + A_{21} \\alpha_2$\n",
    "\n",
    "$ T \\alpha_2 = A_{12} \\alpha_1 + A_{22} \\alpha_2$\n",
    "\n",
    "So $A = \\begin{pmatrix} A_{11} & A_{12}\\\\ A_{21} & A_{22} \\end{pmatrix}$ is the matrix of $T$ relative to the $\\alpha$ basis.\n",
    "\n",
    "Note: $T \\alpha_j = \\sum_{i=1}^n A_{ij} \\alpha_i$ in general.\n",
    "\n",
    "Another way: $A = \\begin{pmatrix} | & | \\\\ T\\alpha_1 & T\\alpha_2 \\\\ | & | \\end{pmatrix}$ in this basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigen stuff and polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **eigenvalue** is a scalar $c$ such that $T \\alpha = c \\alpha$ for some non-zero vector $\\alpha$.\n",
    "\n",
    "In this case $\\alpha$ is an **eigenvector** of $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**: Equivalent:\n",
    "\n",
    "   1) $c$ is an eigenvalue of $T$\n",
    "\n",
    "   2) The operator $(T-cI)$ is not invertible\n",
    "\n",
    "   3) $det(T-cI) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **characteristic polynomial** of $A$ is $f = det(xI - A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T$ is **diagonalizable** if there is a basis for $V$ each vector of which is an eigenvalue of $T$. (not necessarily orthogonal!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why?\n",
    "\n",
    "Suppose $\\{\\alpha_1, \\ldots, \\alpha_n \\}$ is a basis of eigenvectors, with $c_1, \\ldots, c_n$ eigenvalues. Then in this basis $T$ is represented as $D = diag \\{ c_1, \\ldots, c_n \\}$: Let $P$ be the matrix with the $\\alpha_i$ as columns, and $M$ be the matrix representation of $T$ in the standard basis. Then $MP$ has $c_i \\alpha_i$ as columns, and so $MP = P D$ and hence $M = PDP^{-1}$.\n",
    "\n",
    "If the eigenvectors are all orthonormal we would also have $P^{-1} = P^*$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**:\n",
    "    \n",
    "$T$ linear operator with distinct eigenvalues $c_1, \\ldots, c_k$. Let $W_i$ be the null space of $(T-c_iI)$. Equivalent:\n",
    "    \n",
    "1) T is diagonalizable\n",
    "\n",
    "2) The characteristic polynomial of $T$ is $f=(x-c_1)^{d_1} \\cdots (x-c_k)^{d_k}$ and $dim(W_i) = d_i$.\n",
    "\n",
    "3) $dim(W_1) + \\cdots dim(W_k) = dim(V)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **minimal polynomial** of $T$ is the (unique) monic generator of the ideal of polynomials which annihilate $T$.\n",
    "\n",
    "In other words, the polynomial $p$ of smallest degree such that $p(T)=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**:\n",
    "\n",
    "The chatacteristic and minimal polynomials for $T$ have the same roots, except for multiplicities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implies that *if $T$ is diagonilzable, then its minimal polynomial is a product of distinct linear factors*:\n",
    "\n",
    "One of $T-c_1I, \\ldots, T-c_kI$ must send the eigenvect $\\alpha$ to $0$, so $(T-c_1I) \\cdots (T-c_kI)\\alpha = 0$. Since the eigenvects form a basis, $p(T) = (T-c_1I) \\cdots (T-c_kI) = 0 $. So the min. poly. is $p=(x-c_1) \\cdots (x-c_k)$. \n",
    "\n",
    "The converse is true too, but needs more work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cayley-Hamilton Theorem**:\n",
    "\n",
    "Let $f$ be the characteristic polynomial for $T$. then $f(T)=0$, in other words, the minimal polynomial divides the characteristic polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invariant subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Lemma!\n",
    "\n",
    "Let $T$ have minimal polynomial which is a product of linear factors $p = (x-c_1)^{r_1} \\cdots (x-c_k)^{r_k}$. Let $W$ be a proper subset of $V$ ($W \\ne V$). Then there exists a vector $\\alpha$ such that\n",
    "\n",
    "1) $\\alpha \\notin W$\n",
    "\n",
    "2) $(T-cI)\\alpha \\in W$ for some eigenvalue $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorem:\n",
    "\n",
    "$T$ is triangulable if and only if the minimal polynomial for $T$ is a product of linear polynomials over $F$: $p=(x-c_1)^{r_1} \\cdots (x-c_k)^{r_k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good example illustrating how the proof of the previous Lemma is used:\n",
    "\n",
    "\n",
    "We'll show $A = \\begin{pmatrix} 0 & 1 & 0 \\\\ 2 & -2 & 2 \\\\ 2 & -3 & 2 \\end{pmatrix}$ can be put in upper triangular form and do it.\n",
    "\n",
    "The characteristic polynomial happens to be $p(x) = x^3 = (x-0)^3$, so it's a product of linear factors and we can triangularize.\n",
    "\n",
    "How?\n",
    "\n",
    "We start with a vector $v_1 \\notin span((0,0,0))$ but such that $Av_1 \\in span((0,0,0))$. This is the eigenvector associated with eigenvalue $0$: $v_1 = (1,0,-1)$\n",
    "\n",
    "Next we need a vector $v_2$ such that $v_2 \\notin span(v_1)$ but such that $Av_2 \\in span(v_1)$. This is a bit trickier. Start with any vector $\\beta$ not in $span(v_1)$. Say $\\beta = (1,0,0)$. Let $g$ be the poly of smallest deg such that $g(A)\\beta \\in span(v_1)$. We know $g = (x-0)^e$ for some $e=1,2,3$. Since $A\\beta = (0,2,2)$ is not in the span but $A^2\\beta = (2,0,-2)$ is, we have $e=2$. Now $g=(x-0)(x-0) = (x-0)h$. The magic vector is $v_2 = h(A)\\beta = A\\beta = (0,2,2)$.\n",
    "\n",
    "Finally, we need a vector $v_3$ such that $v_3 \\notin span(v_1, v_2)$ but such that $Av_3 \\in span(v_1, v_2)$. Start with any vector $\\beta$ not in $span(v_1, v_2)$. Say $\\beta = (1,0,0)$ again. Let $g$ be the poly of smallest deg such that $g(A)\\beta \\in span(v_1, v_2)$. We know $g = (x-0)^e$ for some $e=1,2,3$. Since $A\\beta = (0,2,2)$ is in the span, we have $e=1$. Now $g=(x-0) \\cdot 1 = (x-0)h$. The magic vector is $v_3 = h(A)\\beta = I\\beta = (1,0,0)$.\n",
    "\n",
    "Check:\n",
    "\n",
    "\n",
    "${\\begin{pmatrix} 1 & 0 & 1 \\\\ 0 & 2 & 0 \\\\ -1 & 2 & 0 \\end{pmatrix}}^{-1} \\begin{pmatrix} 0 & 1 & 0 \\\\ 2 & -2 & 2 \\\\ 2 & -3 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 1 \\\\ 0 & 2 & 0 \\\\ -1 & 2 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 2 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\end{pmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorem:\n",
    "\n",
    "$T$ is diagonalizable if and only if the minimal polynomial of $T$ has the form $p = (x-c_1) \\cdots (x-c_k)$ where there $c_i$ are all distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
